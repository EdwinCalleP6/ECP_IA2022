{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre: Calle Perez Edwin\n",
    "### Laboratorio 9\n",
    "### Sis 420"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfwOfkjclHQx"
   },
   "source": [
    "# Ejercicio de programación Regresión Lineal Multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f0WGMMljlHQz"
   },
   "outputs": [],
   "source": [
    "# utilizado para manejos de directorios y rutas\n",
    "import os\n",
    "\n",
    "# Computacion vectorial y cientifica para python\n",
    "import numpy as np\n",
    "\n",
    "# Librerias para graficación (trazado de gráficos)\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Necesario para graficar superficies 3D\n",
    "\n",
    "# llama a matplotlib a embeber graficas dentro de los cuadernillos\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6-ykOwelHQ0"
   },
   "source": [
    "## 2 Regresión lineal con multiples variables\n",
    "\n",
    "Se implementa la regresion lineal multivariable para predecir el precio de las casas. El archivo `Datasets/ex1data2.txt` contiene un conjunto de entrenamiento de precios de casas en Portland, Oregon. La primera columna es el tamaño de la casa en metros cuadrados, la segunda columna es el numero de cuartos, y la tercera columna es el precio de la casa. \n",
    "\n",
    "<a id=\"section4\"></a>\n",
    "### 2.1 Normalización de caracteristicas\n",
    "\n",
    "Al visualizar los datos se puede observar que las caracteristicas tienen diferentes magnitudes, por lo cual se debe transformar cada valor en una escala de valores similares, esto con el fin de que el descenso por el gradiente pueda converger mas rapidamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6BP5grkxlHQ0",
    "outputId": "cb736fc0-30c8-42a7-a21e-08ad0c106e2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19.     0.    27.9    0.     1.     3.   ]\n",
      " [18.     1.    33.77   1.     0.     2.   ]\n",
      " [28.     1.    33.     3.     0.     2.   ]\n",
      " ...\n",
      " [34.     0.    29.26   3.     0.     2.   ]\n",
      " [33.     1.    35.75   2.     0.     2.   ]\n",
      " [46.     1.    33.345  1.     0.     0.   ]]\n",
      "[16884.924    1725.5523   4449.462   21984.47061  3866.8552   3756.6216\n",
      "  8240.5896   7281.5056   6406.4107  28923.13692  2721.3208  27808.7251\n",
      "  1826.843   11090.7178  39611.7577   1837.237   10797.3362   2395.17155\n",
      " 10602.385   36837.467   13228.84695  4149.736    1137.011   37701.8768\n",
      "  6203.90175 14001.1338  14451.83515 12268.63225  2775.19215 38711.\n",
      " 35585.576    2198.18985  4687.797   13770.0979  51194.55914  1625.43375\n",
      " 15612.19335  2302.3     39774.2763  48173.361    3046.062    4949.7587\n",
      "  6272.4772   6313.759    6079.6715  20630.28351  3393.35635  3556.9223\n",
      " 12629.8967  38709.176    2211.13075  3579.8287  23568.272   37742.5757\n",
      "  8059.6791  47496.49445 13607.36875 34303.1672  23244.7902   5989.52365\n",
      "  8606.2174   4504.6624  30166.61817  4133.64165 14711.7438   1743.214\n",
      " 14235.072    6389.37785  5920.1041  17663.1442  16577.7795   6799.458\n",
      " 11741.726   11946.6259   7726.854   11356.6609   3947.4131   1532.4697\n",
      "  2755.02095  6571.02435  4441.21315  7935.29115 37165.1638  11033.6617\n",
      " 39836.519   21098.55405 43578.9394  11073.176    8026.6666  11082.5772\n",
      "  2026.9741  10942.13205 30184.9367   5729.0053  47291.055    3766.8838\n",
      " 12105.32    10226.2842  22412.6485  15820.699    6186.127    3645.0894\n",
      " 21344.8467  30942.1918   5003.853   17560.37975  2331.519    3877.30425\n",
      "  2867.1196  47055.5321  10825.2537  11881.358    4646.759    2404.7338\n",
      " 11488.31695 30259.99556 11381.3254  19107.7796   8601.3293   6686.4313\n",
      "  7740.337    1705.6245   2257.47525 39556.4945  10115.00885  3385.39915\n",
      " 17081.08     9634.538   32734.1863   6082.405   12815.44495 13616.3586\n",
      " 11163.568    1632.56445  2457.21115  2155.6815   1261.442    2045.68525\n",
      " 27322.73386  2166.732   27375.90478  3490.5491  18972.495   18157.876\n",
      " 20745.9891   5138.2567  40720.55105  9877.6077  10959.6947   1842.519\n",
      "  5125.2157   7789.635    6334.34355 19964.7463   7077.1894   6948.7008\n",
      " 21223.6758  15518.18025 36950.2567  19749.38338 21348.706   36149.4835\n",
      " 10450.552    5152.134    5028.1466  10407.08585  4830.63     6128.79745\n",
      "  2719.27975  4827.90495 13405.3903   8116.68     1694.7964   5246.047\n",
      "  2855.43755 48824.45     6455.86265 10436.096    8823.279    8538.28845\n",
      " 11735.87905  1631.8212   4005.4225   7419.4779   7731.4271  43753.33705\n",
      "  3981.9768   5325.651    6775.961    4922.9159  12557.6053   4883.866\n",
      "  2137.6536  12044.342    1137.4697   1639.5631   5649.715    8516.829\n",
      "  9644.2525  14901.5167   2130.6759   8871.1517  13012.20865 37133.8982\n",
      "  7147.105    4337.7352  11743.299   20984.0936  13880.949    6610.1097\n",
      "  1980.07     8162.71625  3537.703    5002.7827   8520.026    7371.772\n",
      " 10355.641    2483.736    3392.9768  25081.76784  5012.471   10564.8845\n",
      "  5253.524   34779.615   19515.5416  11987.1682   2689.4954  24227.33724\n",
      "  7358.17565  9225.2564   7443.64305 14001.2867   1727.785   12333.828\n",
      "  6710.1919  19444.2658   1615.7667   4463.2051  17352.6803   7152.6714\n",
      " 38511.6283   5354.07465 35160.13457  7196.867   29523.1656  24476.47851\n",
      " 12648.7034   1986.9334   1832.094    4040.55825 12829.4551  47305.305\n",
      " 44260.7499   4260.744   41097.16175 13047.33235 43921.1837   5400.9805\n",
      " 11520.09985 33750.2918  11837.16    17085.2676  24869.8368  36219.40545\n",
      " 20462.99766 46151.1245  17179.522   14590.63205  7441.053    9282.4806\n",
      "  1719.4363  42856.838    7265.7025   9617.66245  2523.1695   9715.841\n",
      "  2803.69785  2150.469   12928.7911   9855.1314  22331.5668  48549.17835\n",
      "  4237.12655 11879.10405  9625.92     7742.1098   9432.9253  14256.1928\n",
      " 47896.79135 25992.82104  3172.018   20277.80751 42112.2356   2156.7518\n",
      "  3906.127    1704.5681  16297.846   21978.6769  38746.3551   9249.4952\n",
      "  6746.7425  24873.3849  12265.5069   4349.462   12646.207   19442.3535\n",
      " 20177.67113  4151.0287  11944.59435  7749.1564   8444.474    1737.376\n",
      " 42124.5153   8124.4084  34838.873    9722.7695   8835.26495 10435.06525\n",
      "  7421.19455  4667.60765  4894.7533  24671.66334 35491.64    11566.30055\n",
      "  2866.091    6600.20595  3561.8889  42760.5022  47928.03     9144.565\n",
      " 48517.56315 24393.6224  13429.0354  11658.37915 19144.57652 13822.803\n",
      " 12142.5786  13937.6665  41919.097    8232.6388  18955.22017 13352.0998\n",
      " 13217.0945  13981.85035 10977.2063   6184.2994   4889.9995   8334.45755]\n",
      "348\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos\n",
    "data = np.loadtxt(os.path.join('Datasets', 'insurance.txt'), delimiter=',')\n",
    "X = data[:, :6]\n",
    "y = data[:, 6]\n",
    "m = y.size\n",
    "\n",
    "# imprimir algunos puntos de datos\n",
    "#print('{:>8s}{:>8s}{:>10s}'.format('X[:,0]', 'X[:, 1]', 'y'))\n",
    "#print('-'*26)\n",
    "#for i in range(10):\n",
    "#    print('{:8.0f}{:8.0f}{:10.0f}'.format(X[i, 0], X[i, 1], y[i]))\n",
    "#print(y)\n",
    "print(X)\n",
    "print(y)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iU_3mwZlHQ1"
   },
   "source": [
    "La desviación estándar es una forma de medir cuánta variación hay en el rango de valores de una característica en particular (la mayoría de los puntos caeran en un rango de ± 2 en relación a la desviaciones estándar de la media); esta es una alternativa a tomar el rango de valores (max-min). En `numpy`, se puede usar la función `std` para calcular la desviacion estandar. \n",
    "\n",
    "Por ejemplo, la caracteristica`X[:, 0]` contiene todos los valores de $x_1$ (tamaño de las casas) en el conjunto de entrenamiento, entonces `np.std(X[:, 0])` calcula la desviacion estandar de los tamaños de las casas.\n",
    "En el momento en que se llama a la función `featureNormalize`, la columna adicional de unos correspondiente a $ x_0 = 1 $ aún no se ha agregado a $ X $. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**Notas para la implementación:** Cuando se normalize una caracteristica, es importante almacenar los valores usados para la normalización - el valor de la media y el valor de la desviación estandar usado para los calculos. Despues de aprender los parametros del modelo, se deseara predecir los precios de casas que no se han visto antes. Dado un nuevo valor de x (area del living room y el numero de dormitorios), primero se debe normalizar x usando la media y la desviacion estandar que se empleo anteriormente en el conjunto de entrenamiento para entrenar el modelo.\n",
    "</div>\n",
    "<a id=\"featureNormalize\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7xFD8H3WlHQ1"
   },
   "outputs": [],
   "source": [
    "def  featureNormalize(X):\n",
    "    X_norm = X.copy()\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "    print(\"---\")\n",
    "    print(mu)\n",
    "    print(\"---\")\n",
    "    mu = np.mean(X, axis = 0)\n",
    "    sigma = np.std(X, axis = 0)\n",
    "    X_norm = (X - mu) / sigma\n",
    "    \n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipL_QsTZlHQ2",
    "outputId": "6110febe-33ec-48d6-e2ef-9920af15a5e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "---\n",
      "[[19.     0.    27.9    0.     1.     3.   ]\n",
      " [18.     1.    33.77   1.     0.     2.   ]\n",
      " [28.     1.    33.     3.     0.     2.   ]\n",
      " ...\n",
      " [34.     0.    29.26   3.     0.     2.   ]\n",
      " [33.     1.    35.75   2.     0.     2.   ]\n",
      " [46.     1.    33.345  1.     0.     0.   ]]\n",
      "Media calculada: [39.59195402  0.50862069 30.67655172  1.09195402  0.23275862  1.49712644]\n",
      "Desviación estandar calculada: [14.39628559  0.49992568  5.61776117  1.19030745  0.42258969  1.10250124]\n",
      "[[-1.43036576 -1.01739261 -0.49424524 -0.91737141  1.81557052  1.36314909]\n",
      " [-1.49982813  0.98290472  0.550655   -0.07725233 -0.55079106  0.45612063]\n",
      " [-0.80520451  0.98290472  0.41358972  1.60298584 -0.55079106  0.45612063]\n",
      " ...\n",
      " [-0.38843033 -1.01739261 -0.25215592  1.60298584 -0.55079106  0.45612063]\n",
      " [-0.4578927   0.98290472  0.90310857  0.76286675 -0.55079106  0.45612063]\n",
      " [ 0.44511801  0.98290472  0.47500209 -0.07725233 -0.55079106 -1.35793628]]\n"
     ]
    }
   ],
   "source": [
    "# llama featureNormalize con los datos cargados\n",
    "X_norm, mu, sigma = featureNormalize(X)\n",
    "\n",
    "print(X)\n",
    "print('Media calculada:', mu)\n",
    "print('Desviación estandar calculada:', sigma)\n",
    "print(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "it9bMYuLlHQ2"
   },
   "source": [
    "Despues de `featureNormalize` la funcion es provada, se añade el temino de interseccion a `X_norm`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nNaGVxgolHQ2"
   },
   "outputs": [],
   "source": [
    "# Añade el termino de interseccion a X\n",
    "# (Columna de unos para X0)\n",
    "X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nbUVohnhlHQ3",
    "outputId": "e4c8efc0-bbe0-4f23-d42c-ba431ea20603"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -1.43036576 -1.01739261 ... -0.91737141  1.81557052\n",
      "   1.36314909]\n",
      " [ 1.         -1.49982813  0.98290472 ... -0.07725233 -0.55079106\n",
      "   0.45612063]\n",
      " [ 1.         -0.80520451  0.98290472 ...  1.60298584 -0.55079106\n",
      "   0.45612063]\n",
      " ...\n",
      " [ 1.         -0.38843033 -1.01739261 ...  1.60298584 -0.55079106\n",
      "   0.45612063]\n",
      " [ 1.         -0.4578927   0.98290472 ...  0.76286675 -0.55079106\n",
      "   0.45612063]\n",
      " [ 1.          0.44511801  0.98290472 ... -0.07725233 -0.55079106\n",
      "  -1.35793628]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzLiIE6NlHQ3"
   },
   "source": [
    "<a id=\"section5\"></a>\n",
    "### 2.2 Descenso por el gradiente\n",
    "\n",
    "En el ejemplo anterior se implemento el descenso por el gradiente para un problema de regresion univariable. La unica diferencia es que ahora existe una caracteristica adicional en la matriz $X$. La función de hipótesis y la regla de actualización del descenso del gradiente por lotes permanecen sin cambios.\n",
    "\n",
    "La implementacion de las funciones `computeCostMulti` y `gradientDescentMulti` son similares a la funcion de costo y función de descenso por el gradiente de la regresión lineal multiple es similar al de la regresion lineal multivariable. Es importante garantizar que el codigo soporte cualquier numero de caracteristicas y esten bien vectorizadas.\n",
    "\n",
    "Se puede utilizar `shape`, propiedad de los arrays `numpy`, para identificar cuantas caracteristicas estan consideradas en el dataset.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**Nota de implementación:** En el caso de multivariables, la función de costo puede se escrita considerando la forma vectorizada de la siguiente manera:\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m}(X\\theta - \\vec{y})^T(X\\theta - \\vec{y}) $$\n",
    "\n",
    "donde:\n",
    "\n",
    "$$ X = \\begin{pmatrix}\n",
    "          - (x^{(1)})^T - \\\\\n",
    "          - (x^{(2)})^T - \\\\\n",
    "          \\vdots \\\\\n",
    "          - (x^{(m)})^T - \\\\ \\\\\n",
    "        \\end{pmatrix} \\qquad \\mathbf{y} = \\begin{bmatrix} y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)} \\\\\\end{bmatrix}$$\n",
    "\n",
    "La version vectorizada es eficiente cuando se trabaja con herramientas de calculo numericos computacional como `numpy`. \n",
    "</div>\n",
    "\n",
    "<a id=\"computeCostMulti\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EQCMN7KqlHQ3"
   },
   "outputs": [],
   "source": [
    "def computeCostMulti(X, y, theta):\n",
    "    # Inicializa algunos valores utiles\n",
    "    m = y.shape[0] # numero de ejemplos de entrenamiento\n",
    "    \n",
    "    J = 0\n",
    "    \n",
    "    h = np.dot(X, theta)\n",
    "    \n",
    "    J = (1/(2 * m)) * np.sum(np.square(np.dot(X, theta) - y))\n",
    "    \n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Vdy_aQUklHQ4"
   },
   "outputs": [],
   "source": [
    "def gradientDescentMulti(X, y, theta, alpha, num_iters):\n",
    "    \n",
    "    # Inicializa algunos valores \n",
    "    m = y.shape[0] # numero de ejemplos de entrenamiento\n",
    "    \n",
    "    # realiza una copia de theta, el cual será acutalizada por el descenso por el gradiente\n",
    "    theta = theta.copy()\n",
    "    \n",
    "    J_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)\n",
    "        J_history.append(computeCostMulti(X, y, theta))\n",
    "    \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8b_GwZslHQ4"
   },
   "source": [
    "#### 3.2.1 Seleccionando coheficientes de aprendizaje\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "sId0DiH9lHQ4",
    "outputId": "0806d03a-be03-4386-f864-4c31fb5a358b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta calculado por el descenso por el gradiente: [14016.42629328  3837.81712577    98.47043536  1933.28329109\n",
      "   651.82056636 10075.29833712  -178.91365953]\n",
      "Cargo(monto) que debe pagar: $33219\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Elegir algun valor para alpha (probar varias alternativas)\n",
    "alpha = 0.01 # alpha = 0.003\n",
    "num_iters = 17000\n",
    "\n",
    "# inicializa theta y ejecuta el descenso por el gradiente\n",
    "theta = np.zeros(7)\n",
    "theta, J_history = gradientDescentMulti(X, y, theta, alpha, num_iters)\n",
    "\n",
    "# Grafica la convergencia del costo\n",
    "pyplot.plot(np.arange(len(J_history)), J_history, lw=2)\n",
    "pyplot.xlabel('Numero de iteraciones')\n",
    "pyplot.ylabel('Costo J')\n",
    "\n",
    "# Muestra los resultados del descenso por el gradiente\n",
    "print('theta calculado por el descenso por el gradiente: {:s}'.format(str(theta)))\n",
    "\n",
    "# Estimar el precio del seguro que pagara sabiendo su edad, genero,masa corporal,hijos,fumador,region\n",
    "X_array = [1,26,1,40.77,3,1,2]\n",
    "X_array[1:7] = (X_array[1:7] - mu) / sigma\n",
    "price = np.dot(X_array, theta)   # Se debe cambiar esto\n",
    "\n",
    "print('Cargo(monto) que debe pagar: ${:.0f}'.format(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "y0aZhWEqlHQ4"
   },
   "outputs": [],
   "source": [
    "X_array = [1,26,1,40.77,3,1,2]\n",
    "X_array[1:7] = (X_array[1:7] - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZ4G9CbJlHQ4",
    "outputId": "ec2aff98-4d92-4c38-b80d-721de47b02a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.9441292297644958,\n",
       " 0.9829047232134214,\n",
       " 1.7967029875816338,\n",
       " 1.6029858376396386,\n",
       " 1.8155705153742392,\n",
       " 0.45612063280512793]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_array[1:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nMzqD8elHQ4"
   },
   "source": [
    "<a id=\"section7\"></a>\n",
    "### 2.3 Ecuacion de la Normal\n",
    "\n",
    "Una manera de calcular rapidamente el modelo de una regresion lineal es:\n",
    "\n",
    "$$ \\theta = \\left( X^T X\\right)^{-1} X^T\\vec{y}$$\n",
    "\n",
    "Utilizando esta formula no requiere que se escale ninguna caracteristica, y se obtendra una solucion exacta con un solo calculo: no hay “bucles de convergencia” como en el descenso por el gradiente. \n",
    "\n",
    "Primero se recargan los datos para garantizar que las variables no esten modificadas. Recordar que no es necesario escalar las caracteristicas, se debe agregar la columna de unos a la matriz $X$ para tener el termino de intersección($\\theta_0$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "C6j77JNmlHQ5"
   },
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "data = np.loadtxt(os.path.join('Datasets', 'insurance.txt'), delimiter=',')\n",
    "X = data[:, :6]\n",
    "y = data[:, 6]\n",
    "m = y.size\n",
    "X = np.concatenate([np.ones((m, 1)), X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gVZdjjk9lHQ5"
   },
   "outputs": [],
   "source": [
    "def normalEqn(X, y):\n",
    "  \n",
    "    theta = np.zeros(X.shape[1])\n",
    "    \n",
    "    theta = np.dot(np.dot(np.linalg.inv(np.dot(X.T,X)),X.T),y)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ybyw-FfolHQ5",
    "outputId": "dde31ad7-2f82-4aa1-d4ea-f1e84e647221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta calculado a partir de la ecuación de la normal: [-13099.68174842    266.58384224    196.97014908    344.13767922\n",
      "    547.60689687  23841.79879729   -162.27978079]\n",
      "numero de acciones que se venderan: $33219\n"
     ]
    }
   ],
   "source": [
    "# Calcula los parametros con la ecuación de la normal\n",
    "theta = normalEqn(X, y);\n",
    "\n",
    "# Muestra los resultados optenidos a partir de la aplicación de la ecuación de la normal\n",
    "print('Theta calculado a partir de la ecuación de la normal: {:s}'.format(str(theta)));\n",
    "\n",
    "\n",
    "X_array = [1,26,1,40.77,3,1,2]\n",
    "price = np.dot(X_array, theta) \n",
    "\n",
    "print('numero de acciones que se venderan: ${:.0f}'.format(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HigToDIXoMi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "reg_lin_mul_01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
